{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "collections.MutableMapping = collections.abc.MutableMapping\n",
    "collections.MutableSequence = collections.abc.MutableSequence\n",
    "collections.MutableSet = collections.abc.MutableSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kortex_api.autogen.client_stubs.ActuatorConfigClientRpc import ActuatorConfigClient\n",
    "from kortex_api.autogen.client_stubs.BaseClientRpc import BaseClient\n",
    "from kortex_api.autogen.client_stubs.BaseCyclicClientRpc import BaseCyclicClient\n",
    "from kortex_api.autogen.messages import Base_pb2, BaseCyclic_pb2, ActuatorConfig_pb2\n",
    "\n",
    "from kortex_api.TCPTransport import TCPTransport\n",
    "from kortex_api.UDPTransport import UDPTransport\n",
    "\n",
    "from kortex_api.RouterClient import RouterClient, RouterClientSendOptions\n",
    "from kortex_api.SessionManager import SessionManager\n",
    "from kortex_api.autogen.messages import Session_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/vertix/Documents/positronic/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# import numpy as np\n",
    "# from pytorch3d.transforms import quaternion_invert, quaternion_multiply, matrix_to_quaternion, quaternion_to_matrix\n",
    "# from pytorch3d.transforms import axis_angle_to_matrix, matrix_to_quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport = TCPTransport()\n",
    "router = RouterClient(transport, RouterClient.basicErrorCallback)\n",
    "transport.connect('192.168.1.10', 10000)\n",
    "\n",
    "session_info = Session_pb2.CreateSessionInfo()\n",
    "session_info.username = \"admin\"\n",
    "session_info.password = \"admin\"\n",
    "session_info.session_inactivity_timeout = 1000 * 1000   # (milliseconds)\n",
    "session_info.connection_inactivity_timeout = 1000 * 1000 # (milliseconds)\n",
    "\n",
    "sessionManager = SessionManager(router)\n",
    "sessionManager.CreateSession(session_info)\n",
    "\n",
    "base = BaseClient(router)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "udp_transport = UDPTransport()\n",
    "upd_router = RouterClient(udp_transport, RouterClient.basicErrorCallback)\n",
    "udp_transport.connect('192.168.1.10', 10001)\n",
    "\n",
    "udp_session = SessionManager(upd_router)\n",
    "udp_session.CreateSession(session_info)\n",
    "base_cyclic = BaseCyclicClient(upd_router)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kinova:\n",
    "    def __init__(self, base, base_cyclic):\n",
    "        self.base = base\n",
    "        self.base_cyclic = base_cyclic\n",
    "        self.base.ClearFaults()\n",
    "\n",
    "    def reset(self):\n",
    "        base_servo_mode = Base_pb2.ServoingModeInformation()\n",
    "        base_servo_mode.servoing_mode = Base_pb2.SINGLE_LEVEL_SERVOING\n",
    "        self.base.SetServoingMode(base_servo_mode)\n",
    "\n",
    "        action_type = Base_pb2.RequestedActionType()\n",
    "        action_type.action_type = Base_pb2.REACH_JOINT_ANGLES\n",
    "        action_list = base.ReadAllActions(action_type)\n",
    "        action_handle = None\n",
    "        for action in action_list.action_list:\n",
    "            if action.name == \"Home\":\n",
    "                action_handle = action.handle\n",
    "\n",
    "        base.ExecuteActionFromReference(action_handle)\n",
    "\n",
    "    @property\n",
    "    def joint_angles(self):\n",
    "        feedback = self.base_cyclic.RefreshFeedback()\n",
    "        return np.array([np.radians(a.position) for a in feedback.actuators])\n",
    "\n",
    "    @property\n",
    "    def position(self):\n",
    "        feedback = self.base_cyclic.RefreshFeedback()\n",
    "        return geom.Transform3D(\n",
    "            np.array([feedback.base.tool_pose_x, feedback.base.tool_pose_y, feedback.base.tool_pose_z]),\n",
    "            geom.Rotation.from_euler(\n",
    "                [feedback.base.tool_pose_theta_x, feedback.base.tool_pose_theta_y, feedback.base.tool_pose_theta_z]))\n",
    "\n",
    "    def set_target_position(self, position):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinova = Kinova(base, base_cyclic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinova.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transform3D(t=[ 0.457 -0.006  0.435], q=[ 0.391  0.854 -0.102  0.329])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kinova.position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_fk(angles):\n",
    "    angles = geom.radians_to_degrees(angles)\n",
    "    angles_pb = Base_pb2.JointAngles()\n",
    "    for i, angle in enumerate(angles):\n",
    "        angles_pb.joint_angles.add(joint_identifier=i, value=angle)\n",
    "    try:\n",
    "        fk_out = base.ComputeForwardKinematics(angles_pb)\n",
    "    except:\n",
    "        print(angles)\n",
    "        raise\n",
    "    return geom.Transform3D(translation=np.array([fk_out.x, fk_out.y, fk_out.z]),\n",
    "                            quaternion=geom.Quaternion.from_euler([fk_out.theta_x, fk_out.theta_y, fk_out.theta_z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-104.44380733   51.20547109 -164.02341569   98.00041812  -57.98826489\n",
      "  -87.75071955  170.94020015]\n",
      "[  4.31584539 -15.28273114  -6.92080085 -85.24894559 106.43111907\n",
      " 111.26756796 -65.73425143]\n",
      "[-118.39674101 -122.98797447 -116.75283472   91.21565432  133.79464857\n",
      "  -64.45777269  113.7114917 ]\n",
      "[-143.57968399    8.07253243 -142.67242919   50.23381637 -128.77935208\n",
      "   54.65040603  -67.91732733]\n",
      "[-173.51054699  -72.99829991  -17.84736523  -30.11004015  -95.67674233\n",
      "  -90.14948521   96.8402083 ]\n",
      "[-169.28964968 -113.02636123 -151.46328342  142.6945743   109.9716173\n",
      "  -16.82859809  130.02563733]\n",
      "[-140.03192264  -75.42778785 -117.70357691  105.71644352   79.62889203\n",
      "  101.6302304    29.39805147]\n",
      "[-98.14680345 -39.40304244 -42.66036865  85.36046725 157.12840189\n",
      "  98.09695008  99.38224919]\n",
      "[-158.95460051  -57.89359495  -31.55875649  -54.2339519    82.32593378\n",
      "   26.44691337  -95.09775556]\n",
      "[134.84521874  17.60690786  73.89118325 -71.65718764 125.65461461\n",
      "  86.89391925 131.79466052]\n",
      "[-148.08443858   30.34188491   46.73273622 -118.91797601  -30.26756578\n",
      "  -69.59158863   58.43814737]\n",
      "[  1.09726355 -10.92818394 -17.26606118  31.89283719 145.46892739\n",
      " -64.62668334  27.64192762]\n",
      "[ -60.7815562   -86.72860727 -160.72614219  137.3187739    92.74883588\n",
      "  -12.88233324  165.51766258]\n"
     ]
    }
   ],
   "source": [
    "max_position = geom.degrees_to_radians(np.array([180, 128.9, 180, 147.8, 180, 120.3, 180]))\n",
    "joint_angles_set = []\n",
    "target_set = []\n",
    "while len(joint_angles_set) < 3200 * 1:\n",
    "    angles = np.random.uniform(-max_position, max_position, size=(7))\n",
    "    try:\n",
    "        target_set.append(robot_fk(angles))\n",
    "        joint_angles_set.append(angles)\n",
    "    except:\n",
    "        continue\n",
    "joint_angles_set = np.array(joint_angles_set)\n",
    "joint_angles_set[:, 0] = -joint_angles_set[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_rotation_matrix(matrix):\n",
    "    U, _, Vt = np.linalg.svd(matrix)\n",
    "    R = np.dot(U, Vt)\n",
    "    # det = np.linalg.det(R)\n",
    "    # Vt[2, :] *= det\n",
    "    # R = np.dot(U, Vt)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodesic_loss(predicted_rotations, true_rotations):\n",
    "    batch_size = predicted_rotations.shape[0]\n",
    "    identity = torch.eye(3, device=predicted_rotations.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "\n",
    "    relative_rotation = torch.bmm(true_rotations.transpose(1, 2), predicted_rotations)\n",
    "    trace = torch.diagonal(relative_rotation, dim1=-2, dim2=-1).sum(-1)\n",
    "    geodesic_distance = torch.acos(torch.clamp((trace - 1) / 2, -1.0, 1.0))\n",
    "    return torch.mean(geodesic_distance)\n",
    "\n",
    "def orthogonality_loss(params):\n",
    "    loss = 0\n",
    "    for i in range(8):\n",
    "        R = params[i, :3, :3]\n",
    "        I = torch.eye(3, device=params.device)\n",
    "        loss += torch.norm(torch.mm(R.t(), R) - I)  # Orthogonality loss\n",
    "        loss += torch.abs(torch.det(R) - 1)  # Determinant loss\n",
    "    return loss / 8\n",
    "\n",
    "def translation_loss(predicted_positions, true_positions):\n",
    "    return nn.MSELoss()(predicted_positions, true_positions)\n",
    "\n",
    "def compute_loss(predicted_positions, true_positions, predicted_rotations, true_rotations, params,\n",
    "                 or_weight=0.1, reg_weight=0.1):\n",
    "    position_loss = translation_loss(predicted_positions, true_positions)\n",
    "    orientation_loss = geodesic_loss(predicted_rotations, true_rotations)\n",
    "    regularization_loss = orthogonality_loss(params)\n",
    "    return position_loss + or_weight * orientation_loss + reg_weight * regularization_loss\n",
    "\n",
    "def sqrt_translation_loss(predicted_positions, true_positions, _1, _2, params):\n",
    "    return torch.sqrt(translation_loss(predicted_positions, true_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(joint_angles_set, target_set, params,\n",
    "                  forward_kinematics_fn, loss_fn,\n",
    "                  val_losses = {'Val Tr': sqrt_translation_loss,\n",
    "                                'Val Rot': lambda _1, _2, p, t, _3:  geodesic_loss(p, t) / np.pi * 180,\n",
    "                                'Var Reg': lambda _1, _2, _3, _4, pms: orthogonality_loss(pms)},\n",
    "                  num_epochs=100, batch_size=32, lr=0.01):\n",
    "    joint_angles = torch.tensor(joint_angles_set, dtype=torch.float32).to(device)\n",
    "    end_effector_positions = torch.tensor([t.translation for t in target_set], dtype=torch.float32).to(device)\n",
    "    end_effector_orientations = torch.tensor([t.quaternion.as_rotation_matrix for t in target_set], dtype=torch.float32).to(device)\n",
    "\n",
    "    train_size = int(0.8 * len(joint_angles))\n",
    "\n",
    "    train_joint_angles = joint_angles[:train_size]\n",
    "    val_joint_angles = joint_angles[train_size:]\n",
    "\n",
    "    train_end_effector_positions = end_effector_positions[:train_size]\n",
    "    val_end_effector_positions = end_effector_positions[train_size:]\n",
    "    train_end_effector_orientations = end_effector_orientations[:train_size]\n",
    "    val_end_effector_orientations = end_effector_orientations[train_size:]\n",
    "\n",
    "    optimizer = optim.Adam([params], lr=lr)\n",
    "\n",
    "    num_batches = train_size // batch_size\n",
    "    train_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        permutation = torch.randperm(train_size)\n",
    "        train_joint_angles = train_joint_angles[permutation]\n",
    "        train_end_effector_positions = train_end_effector_positions[permutation]\n",
    "        train_end_effector_orientations = train_end_effector_orientations[permutation]\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                T_val = forward_kinematics_fn(val_joint_angles, params)\n",
    "                predicted_val_positions = T_val[:, :3, 3]\n",
    "                predicted_val_orientations = T_val[:, :3, :3]\n",
    "\n",
    "                val_result = {}\n",
    "                for val_loss_name, val_loss_fn in val_losses.items():\n",
    "                    val_loss = val_loss_fn(predicted_val_positions, val_end_effector_positions,\n",
    "                                           predicted_val_orientations, val_end_effector_orientations, params)\n",
    "                    val_result[val_loss_name] = val_loss.item()\n",
    "            tl = np.sqrt(train_loss.item() / num_batches)\n",
    "            report = f'Epoch [{epoch}/{num_epochs}], Train L: {tl:.7f}, '\n",
    "            for val_loss_name, val_loss in val_result.items():\n",
    "                report += f'{val_loss_name}: {val_loss:.7f}, '\n",
    "            print(report)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = 0\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "\n",
    "            joint_angles_batch = train_joint_angles[start_idx:end_idx]\n",
    "            end_effector_positions_batch = train_end_effector_positions[start_idx:end_idx]\n",
    "            end_effector_orientations_batch = train_end_effector_orientations[start_idx:end_idx]\n",
    "\n",
    "            T = forward_kinematics_fn(joint_angles_batch, params)\n",
    "            predicted_positions = T[:, :3, 3]\n",
    "            predicted_orientations = T[:, :3, :3]\n",
    "\n",
    "            batch_loss = loss_fn(predicted_positions, end_effector_positions_batch,\n",
    "                                 predicted_orientations, end_effector_orientations_batch, params)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss += batch_loss\n",
    "        train_loss /= num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Transform matrix parametrisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_matrix_3x4(params):\n",
    "    batch_size = params.shape[0]\n",
    "    T = torch.eye(4, device=params.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    T[:, :3, :4] = params\n",
    "    return T\n",
    "\n",
    "def rotation_matrix_around_z(theta):\n",
    "    batch_size = theta.shape[0]\n",
    "    R = torch.eye(4, device=theta.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    R[:, 0, 0] = torch.cos(theta)\n",
    "    R[:, 0, 1] = -torch.sin(theta)\n",
    "    R[:, 1, 0] = torch.sin(theta)\n",
    "    R[:, 1, 1] = torch.cos(theta)\n",
    "    return R\n",
    "\n",
    "def forward_kinematics_3x4(joint_angles, params):\n",
    "    batch_size = joint_angles.shape[0]\n",
    "    T = torch.eye(4, device=joint_angles.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    for i in range(8):\n",
    "        if i < 7:\n",
    "            R_joint = rotation_matrix_around_z(joint_angles[:, i])\n",
    "            T_joint = transformation_matrix_3x4(params[i].unsqueeze(0).repeat(batch_size, 1, 1))\n",
    "            T_joint = torch.bmm(T_joint, R_joint)\n",
    "        else:\n",
    "            T_joint = transformation_matrix_3x4(params[i].unsqueeze(0).repeat(batch_size, 1, 1))\n",
    "        T = torch.bmm(T, T_joint)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region Transform matrix params initialisation\n",
    "clean_initialisation = True\n",
    "if clean_initialisation:\n",
    "    params = torch.eye(3, 4, device=device).unsqueeze(0).repeat(8, 1, 1)\n",
    "    params += 0.01 * torch.randn_like(params)  # Add small random perturbations\n",
    "    params = params.to(device).requires_grad_(True)\n",
    "else:\n",
    "    params = torch.tensor([\n",
    "        [[0.95999, 0.25863, 0.00000, 0.00000],\n",
    "        [0.25983, -0.96103, 0.00000, 0.00000],\n",
    "        [0.00000, 0.00000, 1.00000, 0.17415]],\n",
    "\n",
    "        [[0.96725, 0.00000, -0.25973, -0.05303],\n",
    "        [0.26238, 0.00000, 0.96725, 0.20503],\n",
    "        [0.00000, -1.00155, 0.00000, 0.10893]],\n",
    "\n",
    "        [[0.97877, 0.19192, 0.00000, 0.00000],\n",
    "        [0.00000, 0.00000, -0.99765, -0.34695],\n",
    "        [-0.19310, 0.97878, 0.00000, -0.20027]],\n",
    "\n",
    "        [[0.90814, 0.36822, -0.20204, 0.00000],\n",
    "        [0.19684, 0.05537, 0.97951, 0.02780],\n",
    "        [0.37122, -0.92883, 0.00000, 0.07927]],\n",
    "\n",
    "        [[0.84509, 0.35974, 0.39030, 0.13681],\n",
    "        [0.35497, 0.16276, -0.91869, -0.34235],\n",
    "        [-0.39467, 0.91681, 0.00000, -0.01446]],\n",
    "\n",
    "        [[0.94290, 0.18952, -0.27561, -0.07539],\n",
    "        [0.28330, 0.00000, 0.95991, 0.25185],\n",
    "        [0.17853, -0.98264, 0.00000, -0.06802]],\n",
    "\n",
    "        [[0.99947, 0.00000, 0.00000, 0.02646],\n",
    "        [0.00000, 0.99947, 0.00000, -0.16470],\n",
    "        [0.00000, 0.00000, 0.99947, -0.15307]],\n",
    "\n",
    "        [[1.00000, 0.00000, 0.00000, 0.00000],\n",
    "        [0.00000, 1.00000, 0.00000, 0.00000],\n",
    "        [0.00000, 0.00000, 1.00000, -0.10911]]\n",
    "    ], device=device, requires_grad=True)\n",
    "# endregion initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Train L: 0.0000000, Val Tr: 0.4347759, Val Rot: 128.1339569, Var Reg: 0.0591714, \n",
      "Epoch [10/100], Train L: 0.5129604, Val Tr: 0.3042877, Val Rot: 120.9816513, Var Reg: 0.8561605, \n",
      "Epoch [20/100], Train L: 0.5122877, Val Tr: 0.2932837, Val Rot: 120.8232193, Var Reg: 1.0485711, \n",
      "Epoch [30/100], Train L: 0.5117086, Val Tr: 0.2813696, Val Rot: 121.1250839, Var Reg: 1.1517088, \n",
      "Epoch [40/100], Train L: 0.5112205, Val Tr: 0.2758288, Val Rot: 121.3677063, Var Reg: 1.2857041, \n",
      "Epoch [50/100], Train L: 0.5108935, Val Tr: 0.2728305, Val Rot: 121.5100861, Var Reg: 1.3919470, \n",
      "Epoch [60/100], Train L: 0.5106660, Val Tr: 0.2710274, Val Rot: 121.7244415, Var Reg: 1.4573823, \n",
      "Epoch [70/100], Train L: 0.5104812, Val Tr: 0.2718749, Val Rot: 121.8785019, Var Reg: 1.5109535, \n",
      "Epoch [80/100], Train L: 0.5103269, Val Tr: 0.2727478, Val Rot: 122.0951309, Var Reg: 1.5403166, \n",
      "Epoch [90/100], Train L: 0.5101508, Val Tr: 0.2730571, Val Rot: 122.2616425, Var Reg: 1.5842466, \n"
     ]
    }
   ],
   "source": [
    "# Val Tr: 0.0013704, Var Reg: 0.1003958, reg = 0.01\n",
    "# Val Tr: 0.0015980, Var Reg: 0.0753762, reg = 0.1\n",
    "# Val Tr: 0.0013968, Var Reg: 0.0503261, reg = 0.1 after reg=1, (good_params)\n",
    "training_loop(joint_angles_set, target_set, params, forward_kinematics_3x4,\n",
    "              lambda *args, **kwargs: compute_loss(*args, **kwargs, or_weight=10, reg_weight=0.01),\n",
    "               num_epochs=100, batch_size=32, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99658805\n",
      "0.9975116\n",
      "0.9953971\n",
      "0.99630344\n",
      "0.99839497\n",
      "0.9951809\n",
      "0.9961921\n",
      "0.9987566\n"
     ]
    }
   ],
   "source": [
    "for p in params:\n",
    "    print(np.linalg.det(p[:3, :3].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.84363806,  0.53667235,  0.01604977],\n",
       "        [ 0.536898  ,  0.84345704,  0.01791053],\n",
       "        [ 0.00392521, -0.0237271 ,  0.99971074]], dtype=float32),\n",
       " array([[-0.14482734,  0.09030467,  0.00056035],\n",
       "        [ 0.09195863,  0.1414392 ,  0.00585278],\n",
       "        [ 0.00390666, -0.00212199,  0.14228664]], dtype=float32))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_rotation_matrix(params[0, :3, :3].cpu().detach().numpy()), params[0, :3, :3].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_params = params.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99985 -0.00003 -0.00007]\n",
      " [-0.00003 0.99988 0.00014]\n",
      " [-0.00007 0.00014 1.00011]]\n"
     ]
    }
   ],
   "source": [
    "p_rot_matrix = params[0, :3, :3] @ params[0, :3, :3].t()\n",
    "print(np.array2string(p_rot_matrix.cpu().detach().numpy(), formatter={'float_kind':lambda x: \"%.5f\" % x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transform3D(translation=array([ 0.41683146, -0.02172742,  0.9507421 ], dtype=float32), quaternion=array([ 0.03985714, -0.6964763 , -0.165107  ,  0.04246614], dtype=float32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_fk_res = forward_kinematics_3x4(torch.tensor([[0, 0, 0, np.pi / 3, 0, 0, 0]]).to(device), params)\n",
    "geom.Transform3D(translation=_fk_res[0, :3, 3].cpu().detach().numpy(),\n",
    "                 quaternion=matrix_to_quaternion(_fk_res[0, :3, :3]).cpu().detach().numpy())\n",
    "# print(np.array2string(_fk_res[0].cpu().detach().numpy(), formatter={'float_kind':lambda x: \"%.4f\" % x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transform3D(translation=array([-0.00465913, -0.01732557,  1.1907881 ], dtype=float32), quaternion=array([ 0.00453524, -0.7070728 ,  0.01540003, -0.00438324], dtype=float32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_fk_res = forward_kinematics_3x4(torch.tensor([[0, 0, 0, 0, 0, 0, 0]]).to(device), params)\n",
    "geom.Transform3D(translation=_fk_res[0, :3, 3].cpu().detach().numpy(),\n",
    "                 quaternion=matrix_to_quaternion(_fk_res[0, :3, :3]).cpu().detach().numpy())\n",
    "# print(np.array2string(_fk_res[0].cpu().detach().numpy(), formatter={'float_kind':lambda x: \"%.4f\" % x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transform3D(translation=array([ 0.41688028, -0.0220619 ,  0.95082903]), quaternion=Quaternion([-0.89972798,  0.32380798, -0.1182735 ,  0.26767391]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot_fk(np.array([0, 0, 0, np.pi / 3, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transform3D(translation=array([-0.00454275, -0.01758629,  1.19172156]), quaternion=Quaternion([ 0.76933339,  0.04427104, -0.28721488,  0.56892339]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot_fk(np.array([0, 0, 0, 0, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.77013 -0.63777 0.00152 -0.00038]\n",
      "  [-0.63779 -0.77013 -0.00339 0.00016]\n",
      "  [0.00319 0.00158 -1.00005 0.14570]]\n",
      "\n",
      " [[-0.50354 -0.58628 0.63470 -0.09682]\n",
      "  [0.41384 0.48130 0.77278 -0.11863]\n",
      "  [0.75822 -0.65168 -0.00027 -0.13760]]\n",
      "\n",
      " [[0.38109 -0.53141 0.75626 -0.24756]\n",
      "  [0.43695 -0.61764 -0.65384 0.21475]\n",
      "  [-0.81469 -0.57976 0.00314 0.16431]]\n",
      "\n",
      " [[0.49512 0.30655 0.81292 0.31243]\n",
      "  [-0.69016 -0.42956 0.58226 0.22499]\n",
      "  [0.52771 -0.84953 -0.00111 -0.09528]]\n",
      "\n",
      " [[0.73179 -0.42949 0.52895 -0.19097]\n",
      "  [0.45553 -0.26895 -0.84859 0.30669]\n",
      "  [0.50668 0.86234 -0.00124 -0.39649]]\n",
      "\n",
      " [[-0.49508 -0.68594 0.53346 0.14786]\n",
      "  [0.30728 0.43617 0.84588 0.23362]\n",
      "  [-0.81285 0.58265 -0.00514 0.04368]]\n",
      "\n",
      " [[-0.70391 0.08640 -0.70507 0.09646]\n",
      "  [0.11995 -0.96385 -0.23807 -0.11244]\n",
      "  [-0.70013 -0.25233 0.66808 -0.23853]]\n",
      "\n",
      " [[-0.66671 0.33323 -0.66645 -0.00077]\n",
      "  [-0.33348 0.66649 0.66668 -0.00009]\n",
      "  [-0.66649 -0.66684 0.33322 -0.05638]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array2string(params.cpu().detach().numpy(), formatter={'float_kind':lambda x: \"%.5f\" % x}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### DH Parametrisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation matrix for a single joint using DH parameters\n",
    "def transformation_matrix_dh(theta, d, a, alpha):\n",
    "    if theta.dim() == 0:  # Scalar input\n",
    "        theta = theta.unsqueeze(0)\n",
    "    batch_size = theta.shape[0]\n",
    "    T = torch.eye(4, device=theta.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    T[:, 0, 0] = torch.cos(theta)\n",
    "    T[:, 0, 1] = -torch.sin(theta) * torch.cos(alpha)\n",
    "    T[:, 0, 2] = torch.sin(theta) * torch.sin(alpha)\n",
    "    T[:, 0, 3] = a * torch.cos(theta)\n",
    "    T[:, 1, 0] = torch.sin(theta)\n",
    "    T[:, 1, 1] = torch.cos(theta) * torch.cos(alpha)\n",
    "    T[:, 1, 2] = -torch.cos(theta) * torch.sin(alpha)\n",
    "    T[:, 1, 3] = a * torch.sin(theta)\n",
    "    T[:, 2, 1] = torch.sin(alpha)\n",
    "    T[:, 2, 2] = torch.cos(alpha)\n",
    "    T[:, 2, 3] = d\n",
    "    return T\n",
    "\n",
    "def forward_kinematics_dh(joint_angles, dh_params):\n",
    "    batch_size = joint_angles.shape[0]\n",
    "    T = torch.eye(4, device=joint_angles.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    for i in range(8):\n",
    "        theta, d, a, alpha = dh_params[i]\n",
    "        if i < 7:\n",
    "            T_joint = transformation_matrix_dh(joint_angles[:, i] + theta, d, a, alpha)\n",
    "        else:\n",
    "            T_joint = transformation_matrix_dh(theta.repeat(batch_size), d, a, alpha)\n",
    "        T = torch.bmm(T, T_joint)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dh_parameters(T):\n",
    "    # Extract rotation matrix and position vector\n",
    "    R = T[:3, :3]\n",
    "    p = T[:3, 3]\n",
    "    theta = np.arctan2(R[1, 0], R[0, 0])\n",
    "    d = p[2]\n",
    "    a = np.sqrt(p[0]**2 + p[1]**2)\n",
    "    alpha = np.arctan2(R[2, 1], R[2, 2])\n",
    "\n",
    "    return theta, d, a, alpha\n",
    "\n",
    "# Assuming `params` is the learned transformation matrix parameters\n",
    "learned_params = params.cpu().detach().numpy()\n",
    "\n",
    "# Extract DH parameters from the learned transformation matrices\n",
    "dh_params_list = []\n",
    "for i in range(learned_params.shape[0]):\n",
    "    T = learned_params[i]\n",
    "    theta, d, a, alpha = extract_dh_parameters(T)\n",
    "    dh_params_list.append([theta, d, a, alpha])\n",
    "\n",
    "# Convert the list to a tensor and move to the appropriate device\n",
    "dh_params = torch.tensor(dh_params_list, device=device, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clean_initialisation:\n",
    "    dh_params = torch.zeros(8, 4, device=device, requires_grad=True)\n",
    "else:\n",
    "    dh_params = torch.tensor([\n",
    "        [0.0, 0.15643, 0.0, 3.1416],  # Joint 1\n",
    "        [0.0, -0.12838, 0.005375, 1.5708],  # Joint 2\n",
    "        [0.0, -0.006375, -0.21038, -1.5708],  # Joint 3\n",
    "        [0.0, -0.21038, 0.006375, 1.5708],  # Joint 4\n",
    "        [0.0, -0.006375, -0.20843, -1.5708],  # Joint 5\n",
    "        [0.0, -0.10593, 0.00017505, 1.5708],  # Joint 6\n",
    "        [0.0, -0.00017505, -0.10593, -1.5708],  # Joint 7\n",
    "        [0.0, -0.061525, 0.0, 3.1416]  # End Effector\n",
    "    ], requires_grad=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dh_loss(predicted_positions, true_positions, predicted_rotations, true_rotations, params, reg_weight=0.01):\n",
    "    return translation_loss(predicted_positions, true_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Train L: 0.0000000, Val Tr: 0.2266131, \n",
      "Epoch [10/100], Train L: 0.0249289, Val Tr: 0.2266761, \n",
      "Epoch [20/100], Train L: 0.0249321, Val Tr: 0.2270195, \n",
      "Epoch [30/100], Train L: 0.0249221, Val Tr: 0.2267473, \n",
      "Epoch [40/100], Train L: 0.0249253, Val Tr: 0.2266841, \n",
      "Epoch [50/100], Train L: 0.0249289, Val Tr: 0.2265368, \n",
      "Epoch [60/100], Train L: 0.0249128, Val Tr: 0.2264510, \n",
      "Epoch [70/100], Train L: 0.0249268, Val Tr: 0.2267034, \n",
      "Epoch [80/100], Train L: 0.0249167, Val Tr: 0.2266383, \n",
      "Epoch [90/100], Train L: 0.0249227, Val Tr: 0.2270355, \n"
     ]
    }
   ],
   "source": [
    "training_loop(joint_angles_set, target_set, dh_params, forward_kinematics_dh, dh_loss,\n",
    "               val_losses = {'Val Tr': sqrt_translation_loss},\n",
    "               num_epochs=100, batch_size=32, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Translation and quaternion parametrisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_matrix_tq(params):\n",
    "    batch_size = params.shape[0]\n",
    "    T = torch.eye(4, device=params.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    T[:, :3, :3] = quaternion_to_matrix(params[..., :4] / params[..., :4].norm(dim=1, keepdim=True))\n",
    "    T[:, :3, 3] = params[..., 4:7]\n",
    "    return T\n",
    "\n",
    "def forward_kinematics_tq(joint_angles, params):\n",
    "    batch_size = joint_angles.shape[0]\n",
    "    T = torch.eye(4, device=joint_angles.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    for i in range(8):\n",
    "        if i < 7:\n",
    "            R_joint = rotation_matrix_around_z(joint_angles[:, i])\n",
    "            T_joint = transformation_matrix_tq(params[i].repeat(batch_size, 1))\n",
    "            T_joint = torch.bmm(T_joint, R_joint)\n",
    "        else:\n",
    "            T_joint = transformation_matrix_tq(params[i].repeat(batch_size, 1))\n",
    "        T = torch.bmm(T, T_joint)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_tq = nn.Parameter(torch.randn(8, 7, device=device))\n",
    "params_tq.data[:, :4] = params_tq.data[:, :4] / params_tq.data[:, :4].norm(dim=1, keepdim=True)\n",
    "params_tq.data[:, 4:] = 0.01 * torch.randn(8, 3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_tq = nn.Parameter(torch.randn(8, 7, device=device))\n",
    "for i, p in enumerate(params):\n",
    "    params_tq[i, :4].data.copy_(matrix_to_quaternion(p[:3, :3]).data)\n",
    "    params_tq[i, 4:].data.copy_(p[:3, 3].data)\n",
    "params_tq.data[:, :4] = params_tq.data[:, :4] / params_tq.data[:, :4].norm(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Train L: 0.0000000, Val Tr: 0.0047930, \n",
      "Epoch [10/100], Train L: 0.0001802, Val Tr: 0.0017436, \n",
      "Epoch [20/100], Train L: 0.0001699, Val Tr: 0.0015785, \n",
      "Epoch [30/100], Train L: 0.0001679, Val Tr: 0.0014288, \n",
      "Epoch [40/100], Train L: 0.0001713, Val Tr: 0.0016356, \n",
      "Epoch [50/100], Train L: 0.0001674, Val Tr: 0.0015507, \n",
      "Epoch [60/100], Train L: 0.0001750, Val Tr: 0.0015528, \n",
      "Epoch [70/100], Train L: 0.0001765, Val Tr: 0.0015839, \n",
      "Epoch [80/100], Train L: 0.0001736, Val Tr: 0.0015739, \n",
      "Epoch [90/100], Train L: 0.0001697, Val Tr: 0.0014529, \n"
     ]
    }
   ],
   "source": [
    "training_loop(joint_angles_set, target_set, params_tq, forward_kinematics_tq, dh_loss,\n",
    "               val_losses = {'Val Tr': sqrt_translation_loss},\n",
    "               num_epochs=100, batch_size=32, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAIN = []\n",
    "for p in params_tq:\n",
    "    t = p[4:].cpu().detach().numpy()\n",
    "    q = p[:4].cpu().detach().numpy()\n",
    "    q = q / np.linalg.norm(q)\n",
    "    # print(f'Transform3D({t.tolist()}, Quaternion({q.tolist()})),')\n",
    "    CHAIN.append(geom.Transform3D(translation=t, quaternion=geom.Quaternion(*q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fk(joints, CHAIN):\n",
    "    joints = degrees_to_radians(joints)\n",
    "    joints[0] = -joints[0]  # This is on purpose, the first joint is inverted\n",
    "\n",
    "    result = Transform3D()\n",
    "    for i in range(8):\n",
    "        T_joint = _KINOVA_CHAIN[i]\n",
    "        if i < 7:\n",
    "            R_joint = Transform3D(quaternion=Quaternion.from_euler([0, 0, joints[i]]))\n",
    "            T_joint = T_joint * R_joint\n",
    "        result = result * T_joint\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transform3D(translation=Quaternion([ 0.27638114, -0.31061917,  0.94938417]), quaternion=Quaternion([ 0.6885704 , -0.32237743,  0.61590285,  0.20641523]))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hardware import kinova\n",
    "kinova._forward_kinematics(np.array([np.pi / 4, 0, 0, np.pi / 3, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00039361 0.00118508 0.00093426]\n",
      "[ 0.00050046  0.0001458  -0.00222602]\n",
      "[-2.10653209e-04 -9.50002942e-05 -2.81321447e-04]\n",
      "[-8.52860448e-05  4.45588195e-04  1.17181741e-03]\n",
      "[ 1.23069345e-03  1.32805648e-04 -5.92699297e-05]\n",
      "[ 0.00040665 -0.00016971 -0.00085031]\n",
      "[0.00060344 0.00041321 0.00127315]\n",
      "[0.00151878 0.0019804  0.00334766]\n",
      "[0.00248696 0.00143497 0.00087649]\n",
      "[-0.00064614  0.00062047 -0.00117341]\n"
     ]
    }
   ],
   "source": [
    "for ja, t in zip(joint_angles_set[:10], target_set[:10]):\n",
    "    fk = kinova._forward_kinematics(ja)\n",
    "    print(fk.translation - t.translation)\n",
    "    # print(fk.quaternion.inv * t.quaternion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1109, -0.7073, -0.6982],\n",
       "        [ 0.1523, -0.6821,  0.7152],\n",
       "        [-0.9821, -0.1856,  0.0321]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_kinematics_tq(torch.tensor([[np.pi / 4, 0, 0, np.pi / 3, 0, 0, 0]]).to(device), params_tq)[0, :3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transform3D(translation=array([ 0.27664271, -0.3105503 ,  0.95157391]), quaternion=Quaternion([-0.7116911 ,  0.44604303, -0.51713448, -0.16466126]))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot_fk(np.array([np.pi / 4, 0, 0, np.pi / 3, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.4568536\n",
       "y: -0.005980493\n",
       "z: 0.435407\n",
       "theta_x: 90.21811\n",
       "theta_y: -0.6986531\n",
       "theta_z: 88.07178"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.ComputeForwardKinematics(base.GetMeasuredJointAngles())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00035041754017584026,\n",
       " 15.00699234008789,\n",
       " 179.99844360351562,\n",
       " 229.9932403564453,\n",
       " 359.99859619140625,\n",
       " 54.99531936645508,\n",
       " 89.9994888305664]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.value for a in base.GetMeasuredJointAngles().joint_angles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Axis angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_matrix_axis_angle(params):\n",
    "    batch_size = params.shape[0]\n",
    "    T = torch.eye(4, device=params.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    T[:, :3, :3] = axis_angle_to_matrix(params[..., :3])\n",
    "    T[:, :3, 3] = params[..., 3:6]\n",
    "    return T\n",
    "\n",
    "def forward_kinematics_axis_angle(joint_angles, params):\n",
    "    batch_size = joint_angles.shape[0]\n",
    "    T = torch.eye(4, device=joint_angles.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    for i in range(8):\n",
    "        if i < 7:\n",
    "            R_joint = rotation_matrix_around_z(joint_angles[:, i])\n",
    "            T_joint = transformation_matrix_axis_angle(params[i].repeat(batch_size, 1))\n",
    "            T_joint = torch.bmm(T_joint, R_joint)\n",
    "        else:\n",
    "            T_joint = transformation_matrix_axis_angle(params[i].repeat(batch_size, 1))\n",
    "        T = torch.bmm(T, T_joint)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_axis_angle_params():\n",
    "    params = torch.zeros(8, 6, device=device)\n",
    "    axis = torch.randn(8, 3, device=device)\n",
    "    axis = axis / axis.norm(dim=1, keepdim=True)  # Normalize to unit vectors\n",
    "    angle = torch.randn(8, 1, device=device) * 0.1  # Small random angles\n",
    "    params[:, :3] = axis * angle\n",
    "    params[:, 3:] = torch.randn(8, 3, device=device) * 0.1  # Small random translations\n",
    "    return nn.Parameter(params)\n",
    "\n",
    "params_axis_angle = init_axis_angle_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Train L: 0.0000000, Val Tr: 0.5458503, \n",
      "Epoch [10/100], Train L: 0.0403375, Val Tr: 0.3598517, \n",
      "Epoch [20/100], Train L: 0.0403006, Val Tr: 0.3601849, \n",
      "Epoch [30/100], Train L: 0.0399200, Val Tr: 0.3565348, \n",
      "Epoch [40/100], Train L: 0.0392160, Val Tr: 0.3507843, \n",
      "Epoch [50/100], Train L: 0.0390921, Val Tr: 0.3493647, \n",
      "Epoch [60/100], Train L: 0.0390696, Val Tr: 0.3490727, \n",
      "Epoch [70/100], Train L: 0.0390726, Val Tr: 0.3492168, \n",
      "Epoch [80/100], Train L: 0.0390615, Val Tr: 0.3492782, \n",
      "Epoch [90/100], Train L: 0.0390498, Val Tr: 0.3486316, \n"
     ]
    }
   ],
   "source": [
    "training_loop(joint_angles_set, target_set, params_axis_angle, forward_kinematics_axis_angle, dh_loss,\n",
    "               val_losses = {'Val Tr': sqrt_translation_loss},\n",
    "               num_epochs=100, batch_size=32, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exp map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_map_to_matrix(exp_map):\n",
    "    theta = torch.norm(exp_map, dim=-1, keepdim=True)\n",
    "    w = exp_map / (theta + 1e-8)\n",
    "    wx = torch.zeros(exp_map.shape[0], 3, 3, device=exp_map.device)\n",
    "    wx[:, 0, 1], wx[:, 0, 2], wx[:, 1, 2] = -w[:, 2], w[:, 1], -w[:, 0]\n",
    "    wx[:, 1, 0], wx[:, 2, 0], wx[:, 2, 1] = w[:, 2], -w[:, 1], w[:, 0]\n",
    "    I = torch.eye(3, device=exp_map.device).unsqueeze(0)\n",
    "    R = I + torch.sin(theta).unsqueeze(-1) * wx + (1 - torch.cos(theta)).unsqueeze(-1) * torch.bmm(wx, wx)\n",
    "    return R\n",
    "\n",
    "def transformation_matrix_exp_map(params):\n",
    "    batch_size = params.shape[0]\n",
    "    T = torch.eye(4, device=params.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    T[:, :3, :3] = exp_map_to_matrix(params[..., :3])\n",
    "    T[:, :3, 3] = params[..., 3:6]\n",
    "    return T\n",
    "\n",
    "def forward_kinematics_exp_map(joint_angles, params):\n",
    "    batch_size = joint_angles.shape[0]\n",
    "    T = torch.eye(4, device=joint_angles.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    for i in range(8):\n",
    "        if i < 7:\n",
    "            R_joint = rotation_matrix_around_z(joint_angles[:, i])\n",
    "            T_joint = transformation_matrix_exp_map(params[i].repeat(batch_size, 1))\n",
    "            T_joint = torch.bmm(T_joint, R_joint)\n",
    "        else:\n",
    "            T_joint = transformation_matrix_exp_map(params[i].repeat(batch_size, 1))\n",
    "        T = torch.bmm(T, T_joint)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_exp_map_params():\n",
    "    params = torch.zeros(8, 6, device=device)\n",
    "    params[:, :3] = torch.randn(8, 3, device=device) * 0.1  # Small random exp map values\n",
    "    params[:, 3:] = torch.randn(8, 3, device=device) * 0.1  # Small random translations\n",
    "    return nn.Parameter(params)\n",
    "\n",
    "params_exp_map = init_exp_map_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Train L: 0.0000000, Val Tr: 0.4556128, \n",
      "Epoch [10/100], Train L: 0.0402838, Val Tr: 0.3595736, \n",
      "Epoch [20/100], Train L: 0.0401519, Val Tr: 0.3589512, \n",
      "Epoch [30/100], Train L: 0.0398864, Val Tr: 0.3565167, \n",
      "Epoch [40/100], Train L: 0.0394437, Val Tr: 0.3524919, \n",
      "Epoch [50/100], Train L: 0.0391771, Val Tr: 0.3501579, \n",
      "Epoch [60/100], Train L: 0.0390972, Val Tr: 0.3492624, \n",
      "Epoch [70/100], Train L: 0.0390804, Val Tr: 0.3492976, \n",
      "Epoch [80/100], Train L: 0.0390937, Val Tr: 0.3493089, \n",
      "Epoch [90/100], Train L: 0.0390619, Val Tr: 0.3491254, \n"
     ]
    }
   ],
   "source": [
    "training_loop(joint_angles_set, target_set, params_exp_map, forward_kinematics_exp_map, dh_loss,\n",
    "               val_losses = {'Val Tr': sqrt_translation_loss},\n",
    "               num_epochs=100, batch_size=32, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Dual quaternions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_quaternion_to_matrix(dq):\n",
    "    q_real, q_dual = dq[..., :4], dq[..., 4:]\n",
    "    R = quaternion_to_matrix(q_real)\n",
    "    t = 2 * quaternion_multiply(q_dual, quaternion_invert(q_real))[..., :3]\n",
    "    return R, t\n",
    "\n",
    "def transformation_matrix_dual_quaternion(params):\n",
    "    batch_size = params.shape[0]\n",
    "    T = torch.eye(4, device=params.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    R, t = dual_quaternion_to_matrix(params)\n",
    "    T[:, :3, :3] = R\n",
    "    T[:, :3, 3] = t\n",
    "    return T\n",
    "\n",
    "def forward_kinematics_dual_quaternion(joint_angles, params):\n",
    "    batch_size = joint_angles.shape[0]\n",
    "    T = torch.eye(4, device=joint_angles.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    for i in range(8):\n",
    "        if i < 7:\n",
    "            R_joint = rotation_matrix_around_z(joint_angles[:, i])\n",
    "            T_joint = transformation_matrix_dual_quaternion(params[i].unsqueeze(0).repeat(batch_size, 1))\n",
    "            T_joint = torch.bmm(T_joint, R_joint)\n",
    "        else:\n",
    "            T_joint = transformation_matrix_dual_quaternion(params[i].unsqueeze(0).repeat(batch_size, 1))\n",
    "        T = torch.bmm(T, T_joint)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dual_quaternion_params():\n",
    "    params = torch.zeros(8, 8, device=device)\n",
    "    # Real part (rotation)\n",
    "    params[:, :4] = torch.randn(8, 4, device=device)\n",
    "    params[:, :4] = params[:, :4] / params[:, :4].norm(dim=1, keepdim=True)  # Normalize\n",
    "    # Dual part (translation)\n",
    "    params[:, 4:7] = torch.randn(8, 3, device=device) * 0.1  # Small random translations\n",
    "    params[:, 7] = 0  # Last component of dual part is typically 0\n",
    "    return nn.Parameter(params)\n",
    "\n",
    "params_dual_quaternion = init_dual_quaternion_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Train L: 0.0000000, Val Tr: 0.3411884, \n",
      "Epoch [10/100], Train L: 0.0461037, Val Tr: 0.3638723, \n",
      "Epoch [20/100], Train L: 0.0382955, Val Tr: 0.3412696, \n",
      "Epoch [30/100], Train L: 0.0382836, Val Tr: 0.3421803, \n",
      "Epoch [40/100], Train L: 0.0382783, Val Tr: 0.3410841, \n",
      "Epoch [50/100], Train L: 0.0382734, Val Tr: 0.3415281, \n",
      "Epoch [60/100], Train L: 0.0404471, Val Tr: 0.3594979, \n",
      "Epoch [70/100], Train L: 0.0403403, Val Tr: 0.3603511, \n",
      "Epoch [80/100], Train L: 0.0403492, Val Tr: 0.3608832, \n",
      "Epoch [90/100], Train L: 0.0403230, Val Tr: 0.3608685, \n"
     ]
    }
   ],
   "source": [
    "training_loop(joint_angles_set, target_set, params_dual_quaternion, forward_kinematics_dual_quaternion, dh_loss,\n",
    "               val_losses = {'Val Tr': sqrt_translation_loss},\n",
    "               num_epochs=100, batch_size=32, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Inverse kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geom\n",
    "import importlib\n",
    "importlib.reload(geom)\n",
    "\n",
    "from hardware import kinova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_KINOVA_CHAIN = [\n",
    "    geom.Transform3D([-7.732256199233234e-05, 0.0004820869071409106, 0.1384558230638504],\n",
    "                geom.Quaternion(0.9999598860740662, -0.0014847038546577096, -0.0004586570430546999, 0.008817019872367382)),\n",
    "    geom.Transform3D([-0.0020223343744874, -0.11016443371772766, 0.14530658721923828],\n",
    "                geom.Quaternion(0.7064821720123291, -0.7075875997543335, 0.014157610014081001, -0.0015306948916986585)),\n",
    "    geom.Transform3D([-0.012653934769332409, -0.6051681637763977, 0.0995088443160057],\n",
    "                geom.Quaternion(0.7058353424072266, -0.7080992460250854, 0.019063977524638176, 0.005337915848940611)),\n",
    "    geom.Transform3D([0.00476058479398489, 0.14438331127166748, 0.18294934928417206],\n",
    "                geom.Quaternion(0.70661860704422, 0.7065088152885437, -0.03622652217745781, 0.014936398714780807)),\n",
    "    geom.Transform3D([-0.031046129763126373, -0.4425973892211914, 0.13292159140110016],\n",
    "                geom.Quaternion(0.7047972083091736, -0.7014123201370239, 0.09579798579216003, 0.045874472707509995)),\n",
    "    geom.Transform3D([0.028989970684051514, 0.12411590665578842, 0.129145547747612],\n",
    "                geom.Quaternion(0.703943133354187, 0.6839388608932495, -0.1895177811384201, 0.027831479907035828)),\n",
    "    geom.Transform3D([-0.051960721611976624, -0.15933051705360413, 0.0792686715722084],\n",
    "                geom.Quaternion(0.9999746084213257, 0.0043069422245025635, -0.0023099626414477825, 0.005186134018003941)),\n",
    "    geom.Transform3D([0.00040886219358071685, -0.000173802807694301, 0.04850476235151291],\n",
    "                geom.Quaternion(0.9999657869338989, 0.0035003339871764183, -0.0015276813646778464, 0.007339356932789087)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = joint_angles_set[0]\n",
    "test[0] = -test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 35.11296165,  18.35642287, 153.17966586,  95.4550201 ,\n",
       "       103.89915645,  17.13910297,  45.79967953])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_degrees = geom.radians_to_degrees(test)\n",
    "test_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 35.10227907,  18.40239598, 153.43369245,  95.44563768,\n",
       "       103.9076728 ,  16.44754914,  46.24153973])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_inverse_kinematics(kinova._forward_kinematics(test_degrees), test_degrees + 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transform3D(t=[-0.35   0.041  0.793], q=[-0.189  0.979 -0.019 -0.077])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_forward_kinematics(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares\n",
    "def _inverse_kinematics(target, initial_position=None):\n",
    "    if initial_position is None:\n",
    "        initial_position = np.zeros(7)\n",
    "    initial_position = np.array(initial_position, dtype=np.float64)\n",
    "    target = target.as_matrix\n",
    "\n",
    "    def objective_function(joint_angles):\n",
    "        fk_result = kinova._forward_kinematics_matrix(joint_angles)\n",
    "        position_error = fk_result[:3, 3] - target[:3, 3]\n",
    "        orientation_error = 0.1 * (fk_result[:3, :3] - target[:3, :3])\n",
    "        regularization = 0.0001 * geom.degrees_to_radians(np.linalg.norm(joint_angles - initial_position))\n",
    "        return np.concatenate((position_error, orientation_error.flatten(), [regularization]))\n",
    "\n",
    "    result = least_squares(objective_function, initial_position, method='lm')\n",
    "    return result.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward_kinematics(joints):  # joints in radians\n",
    "    joints = np.array(joints)\n",
    "    joints[0] = -joints[0]  # This is on purpose, the first joint is inverted\n",
    "\n",
    "    result = geom.Transform3D()\n",
    "    for i in range(8):\n",
    "        T_joint = _KINOVA_CHAIN[i]\n",
    "        if i < 7:\n",
    "            R_joint = geom.Transform3D(quaternion=geom.Quaternion.from_euler([0, 0, joints[i]]))\n",
    "            T_joint = T_joint * R_joint\n",
    "        result = result * T_joint\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transform3D(t=[ 0.276 -0.311  0.949], q=[ 0.689 -0.322  0.616  0.206])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_forward_kinematics(np.array([np.pi / 4, 0, 0, np.pi / 3, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares\n",
    "\n",
    "def inverse_kinematics(target, initial_position=None):\n",
    "    if initial_position is None:\n",
    "        initial_position = np.zeros(7)\n",
    "    initial_position = np.array(initial_position, dtype=np.float64)\n",
    "\n",
    "    def objective_function(joint_angles):\n",
    "        fk_result = _forward_kinematics(joint_angles)\n",
    "        position_error = fk_result.translation - target.translation.astype(np.float64)\n",
    "        orientation_error = 0.1 * (fk_result.quaternion.as_rotation_matrix - target.quaternion.as_rotation_matrix)\n",
    "        regularization = 0.01 * np.linalg.norm(joint_angles)\n",
    "        return np.concatenate((position_error, orientation_error.flatten(), [regularization]))\n",
    "\n",
    "    result = least_squares(objective_function, initial_position, method='lm', ftol=1e-10)\n",
    "    return result.x, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.57305105,  2.08830299, -9.49433737, -7.58956219,  4.10714708,\n",
       "        3.72853255, -0.07694274])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, _ = inverse_kinematics(target_set[0], initial_position=res)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     message: `ftol` termination condition is satisfied.\n",
       "     success: True\n",
       "      status: 2\n",
       "         fun: [-6.176e-03 -2.678e-03 ... -1.197e-02  1.463e-01]\n",
       "           x: [ 5.573e+00  2.088e+00 -9.494e+00 -7.590e+00  4.107e+00\n",
       "                3.729e+00 -7.694e-02]\n",
       "        cost: 0.010894393942519155\n",
       "         jac: [[ 3.122e-01 -2.924e-01 ... -2.884e-02 -8.125e-05]\n",
       "               [-2.338e-01 -2.514e-01 ...  1.284e-01 -2.305e-04]\n",
       "               ...\n",
       "               [-2.900e-04  7.566e-02 ... -8.515e-04 -3.794e-04]\n",
       "               [ 3.810e-03  1.428e-03 ...  2.549e-03 -5.260e-05]]\n",
       "        grad: [ 2.478e-09  1.805e-08 -5.050e-09 -4.392e-08 -5.060e-08\n",
       "               -1.453e-08  8.316e-09]\n",
       "  optimality: 5.0596153475492736e-08\n",
       " active_mask: [0 0 0 0 0 0 0]\n",
       "        nfev: 200\n",
       "        njev: None"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.71013425,  2.08830299,  3.07203325, -1.30637689, -2.17603823,\n",
       "       -2.55465276, -0.07694274])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp_joints(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.57305105,  2.08830299, -9.49433737, -7.58956219,  4.10714708,\n",
       "         3.72853255, -0.07694274]),\n",
       " Transform3D(t=[ 0.234  0.312 -0.102], q=[ 0.228 -0.585 -0.195  0.753]),\n",
       " Transform3D(t=[ 0.24   0.315 -0.105], q=[-0.227  0.533  0.193 -0.792]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TCPTransport.send] ERROR: None\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vertix/miniconda3/envs/positronic/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/vertix/miniconda3/envs/positronic/lib/python3.11/site-packages/kortex_api/SessionManager.py\", line 125, in run\n",
      "    self.parent.KeepAlive(options=options)\n",
      "  File \"/home/vertix/miniconda3/envs/positronic/lib/python3.11/site-packages/kortex_api/autogen/client_stubs/SessionClientRpc.py\", line 59, in KeepAlive\n",
      "    future = self.router.send(None, 1, SessionFunctionUid.uidKeepAlive, deviceId, options)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vertix/miniconda3/envs/positronic/lib/python3.11/site-packages/kortex_api/RouterClient.py\", line 71, in send\n",
      "    self.transport.send(payloadMsgFrame)\n",
      "  File \"/home/vertix/miniconda3/envs/positronic/lib/python3.11/site-packages/kortex_api/TCPTransport.py\", line 85, in send\n",
      "    raise ex\n",
      "  File \"/home/vertix/miniconda3/envs/positronic/lib/python3.11/site-packages/kortex_api/TCPTransport.py\", line 80, in send\n",
      "    self.sock.sendall(payload)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 104] Connection reset by peer\n",
      "[Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "res, _forward_kinematics(res), target_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transform3D(t=[ 0.24   0.315 -0.105], q=[-0.227  0.533  0.193 -0.792])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transform3D(translation=array([-0.23788337,  0.13711733,  1.13880122]), quaternion=Quaternion([-0.96724907,  0.18783113, -0.13580628, -0.10346672]))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_joints(joints):\n",
    "    return np.mod(joints + np.pi, 2 * np.pi) - np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_position = np.zeros(7)\n",
    "target = target_set[0]\n",
    "\n",
    "def objective_function(joint_angles):\n",
    "    fk_result = _forward_kinematics(joint_angles)\n",
    "    position_error = fk_result.translation - target.translation\n",
    "    orientation_error = 0.1 * (fk_result.quaternion.as_rotation_matrix - target.quaternion.as_rotation_matrix)\n",
    "    regularization = 0.1 * np.linalg.norm(joint_angles)\n",
    "    return np.concatenate((position_error, orientation_error.flatten(), [regularization]))\n",
    "\n",
    "result = least_squares(objective_function, initial_position, method='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42775674,  2.83370908,  0.84918635, -0.89696527, -0.15843906,\n",
       "       -1.3713416 ,  0.01809427])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp_joints(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Transform3D(t=[ 0.285  0.393 -0.122], q=[ 0.323 -0.723 -0.053  0.608]),\n",
       " Transform3D(t=[ 0.24   0.315 -0.105], q=[-0.227  0.533  0.193 -0.792]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_forward_kinematics(clamp_joints(result.x)), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "positronic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
